{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the master dataframe\n",
    "df_10k = pd.read_csv('../data/askme-qa/raw_data_10k.csv')\n",
    "\n",
    "# Directory structure\n",
    "base_dir = '../data/hitl'\n",
    "annotators = ['HITL_Alex', 'HITL_Atheer', 'HITL_Hend', 'HITL_Xiaoyuan']\n",
    "file_names = ['Copy of answers_samples.xlsx', 'Copy of questions_samples.xlsx', 'Copy of questions_zs_samples.xlsx']\n",
    "\n",
    "# Initialize empty DataFrames for each type of samples\n",
    "df_answers = None\n",
    "df_questions = None\n",
    "df_questions_zs = None\n",
    "\n",
    "# Iterate over each annotator and each file\n",
    "for annotator in annotators:\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(base_dir, annotator, file_name)\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Drop \"instructions\" column and unnamed columns\n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "        if 'instructions' in df.columns:\n",
    "            df = df.drop(columns=['instructions'])\n",
    "        if 'Comments' in df.columns:\n",
    "            df = df.drop(columns=['Comments'])\n",
    "        # Drop columns with names that are not in English\n",
    "        df = df.drop(columns=[col for col in df.columns if not col.isascii()])\n",
    "\n",
    "        # Rename \"annotation\" column to include the annotator's name\n",
    "        if 'annotation' in df.columns:\n",
    "            annotator_name = annotator.split('_')[-1].lower()\n",
    "            df = df.rename(columns={'annotation': f'annotation_{annotator_name}'})\n",
    "            annotation_col = df[[f'annotation_{annotator_name}']]  # Select only the renamed annotation column\n",
    "\n",
    "            # Merge data to respective DataFrames horizontally\n",
    "            if 'answers' in file_name:\n",
    "                if df_answers is None:\n",
    "                    df_answers = df[['answer_id']].join(annotation_col)\n",
    "                else:\n",
    "                    df_answers = df_answers.join(annotation_col, rsuffix=f'_{annotator_name}')\n",
    "            elif 'questions_zs' in file_name:\n",
    "                if df_questions_zs is None:\n",
    "                    df_questions_zs = df[['question_id']].join(annotation_col)\n",
    "                else:\n",
    "                    df_questions_zs = df_questions_zs.join(annotation_col, rsuffix=f'_{annotator_name}')\n",
    "            else:  # 'questions' in file_name\n",
    "                if df_questions is None:\n",
    "                    df_questions = df[['question_id']].join(annotation_col)\n",
    "                else:\n",
    "                    df_questions = df_questions.join(annotation_col, rsuffix=f'_{annotator_name}')\n",
    "\n",
    "# Append additional fields from df_10k\n",
    "df_answers = df_answers.merge(df_10k[['id_answer', 'value']], left_on='answer_id', right_on='id_answer', how='left').drop(columns=['id_answer'])\n",
    "df_questions_zs = df_questions_zs.merge(df_10k[['question_id', 'is_answerable_zs']], on='question_id', how='left')\n",
    "df_questions = df_questions.merge(df_10k[['question_id', 'is_answerable_ic']], on='question_id', how='left')\n",
    "\n",
    "# Rename columns\n",
    "df_questions = df_questions.rename(columns={'is_answerable_ic': 'annotation_llama3_70b'})\n",
    "df_questions_zs = df_questions_zs.rename(columns={'is_answerable_zs': 'annotation_llama3_70b'})\n",
    "df_answers = df_answers.rename(columns={'value': 'annotation_llama3_70b'})\n",
    "\n",
    "# Replace Y with True and N with False for all annotation columns\n",
    "for col in df_questions.columns:\n",
    "    if col.startswith('annotation_'):\n",
    "        df_questions[col] = df_questions[col].replace({'Y': True, 'N': False})\n",
    "for col in df_questions_zs.columns:\n",
    "    if col.startswith('annotation_'):\n",
    "        df_questions_zs[col] = df_questions_zs[col].replace({'Y': True, 'N': False})\n",
    "for col in df_answers.columns:\n",
    "    if col.startswith('annotation_'):\n",
    "        df_answers[col] = df_answers[col].replace({'Y': True, 'N': False})\n",
    "\n",
    "# Save the updated DataFrames to CSV files\n",
    "df_questions.to_csv('../data/hitl/questions.csv', index=False)\n",
    "df_questions_zs.to_csv('../data/hitl/questions_zs.csv', index=False)\n",
    "df_answers.to_csv('../data/hitl/answers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>annotation_alex</th>\n",
       "      <th>annotation_atheer</th>\n",
       "      <th>annotation_hend</th>\n",
       "      <th>annotation_xiaoyuan</th>\n",
       "      <th>annotation_llama3_70b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36261</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36261</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39026</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39026</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4635</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3509</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2839</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2839</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>33316</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>33316</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_id annotation_alex annotation_atheer annotation_hend  \\\n",
       "0          36261            True               NaN            True   \n",
       "1          36261            True               NaN            True   \n",
       "2          39026            True               NaN            True   \n",
       "3          39026            True               NaN            True   \n",
       "4           4635            True               NaN            True   \n",
       "..           ...             ...               ...             ...   \n",
       "195         3509           False              True             NaN   \n",
       "196         2839            True             False             NaN   \n",
       "197         2839            True             False             NaN   \n",
       "198        33316            True              True             NaN   \n",
       "199        33316            True              True             NaN   \n",
       "\n",
       "    annotation_xiaoyuan  annotation_llama3_70b  \n",
       "0                  True                   True  \n",
       "1                  True                   True  \n",
       "2                  True                   True  \n",
       "3                  True                   True  \n",
       "4                  True                   True  \n",
       "..                  ...                    ...  \n",
       "195               False                   True  \n",
       "196                True                   True  \n",
       "197                True                   True  \n",
       "198               False                   True  \n",
       "199               False                   True  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Human Correlation for Answers: 0.8512799168548875\n",
      "Average Human-Machine Correlation for Answers: 0.76844814051456\n",
      "Average Human Correlation for Questions: 0.09792867290069808\n",
      "Average Human-Machine Correlation for Questions: 0.0442966417395686\n",
      "Average Human Correlation for Questions ZS: 0.2775558123462398\n",
      "Average Human-Machine Correlation for Questions ZS: 0.29006448642906507\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate average correlation between human annotators\n",
    "def average_human_correlation(df):\n",
    "    annotator_columns = [col for col in df.columns if col.startswith('annotation_') and col != 'annotation_llama3_70b']\n",
    "    n = len(annotator_columns)\n",
    "    correlations = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            common_data = df[[annotator_columns[i], annotator_columns[j]]].dropna()\n",
    "            if not common_data.empty and common_data[annotator_columns[i]].nunique() > 1 and common_data[annotator_columns[j]].nunique() > 1:\n",
    "                corr, _ = pearsonr(common_data[annotator_columns[i]], common_data[annotator_columns[j]])\n",
    "                correlations.append(corr)\n",
    "\n",
    "    return sum(correlations) / len(correlations) if correlations else 0\n",
    "\n",
    "# Function to calculate average correlation between human annotators and machine annotator\n",
    "def average_human_machine_correlation(df):\n",
    "    human_columns = [col for col in df.columns if col.startswith('annotation_') and col != 'annotation_llama3_70b']\n",
    "    machine_column = 'annotation_llama3_70b'\n",
    "    correlations = []\n",
    "\n",
    "    for human_col in human_columns:\n",
    "        common_data = df[[human_col, machine_column]].dropna()\n",
    "        if not common_data.empty and common_data[human_col].nunique() > 1 and common_data[machine_column].nunique() > 1:\n",
    "            corr, _ = pearsonr(common_data[human_col], common_data[machine_column])\n",
    "            correlations.append(corr)\n",
    "\n",
    "    return sum(correlations) / len(correlations) if correlations else 0\n",
    "\n",
    "# Calculate correlations for each type of sample\n",
    "avg_human_corr_answers = average_human_correlation(df_answers)\n",
    "avg_human_machine_corr_answers = average_human_machine_correlation(df_answers)\n",
    "\n",
    "avg_human_corr_questions = average_human_correlation(df_questions)\n",
    "avg_human_machine_corr_questions = average_human_machine_correlation(df_questions)\n",
    "\n",
    "avg_human_corr_questions_zs = average_human_correlation(df_questions_zs)\n",
    "avg_human_machine_corr_questions_zs = average_human_machine_correlation(df_questions_zs)\n",
    "\n",
    "# Print the results\n",
    "print(\"Average Human Correlation for Answers:\", avg_human_corr_answers)\n",
    "print(\"Average Human-Machine Correlation for Answers:\", avg_human_machine_corr_answers)\n",
    "\n",
    "print(\"Average Human Correlation for Questions:\", avg_human_corr_questions)\n",
    "print(\"Average Human-Machine Correlation for Questions:\", avg_human_machine_corr_questions)\n",
    "\n",
    "print(\"Average Human Correlation for Questions ZS:\", avg_human_corr_questions_zs)\n",
    "print(\"Average Human-Machine Correlation for Questions ZS:\", avg_human_machine_corr_questions_zs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
